{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93649017-1757-413a-8fec-6c8676516550",
   "metadata": {},
   "source": [
    "# Unit 2. A gentle introduction to audio applications\n",
    "\n",
    "## Audio classification with a pipeline\n",
    "\n",
    "Please see [https://huggingface.co/learn/audio-course/chapter2/audio_classification_pipeline#audio-classification-with-a-pipeline](https://huggingface.co/learn/audio-course/chapter2/audio_classification_pipeline#audio-classification-with-a-pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "046c27ef-f65c-4bb0-9cd7-834ac36d7775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/foo/lib/python3.9/site-packages/datasets/load.py:1486: FutureWarning: The repository for PolyAI/minds14 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/PolyAI/minds14\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import Audio\n",
    "\n",
    "minds = load_dataset(\"PolyAI/minds14\", name=\"en-AU\", split=\"train\")\n",
    "\n",
    "# \"upsample\" to 16 kHz\n",
    "minds = minds.cast_column(\"audio\", Audio(sampling_rate=16_000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf448fa6-f0a3-4155-9731-663732e2b975",
   "metadata": {},
   "source": [
    "## ???\n",
    "\n",
    "[`anton-l/xtreme_s_xlsr_300m_minds14` model card](https://huggingface.co/anton-l/xtreme_s_xlsr_300m_minds14#xtreme_s_xlsr_300m_minds14):\n",
    "\n",
    "> This model is a fine-tuned version of [`facebook/wav2vec2-xls-r-300m`](https://huggingface.co/facebook/wav2vec2-xls-r-300m#wav2vec2-xls-r-300m) on the GOOGLE/XTREME_S - MINDS14.ALL dataset (sic). ([`google/xtreme_s`](https://huggingface.co/datasets/google/xtreme_s#xtreme-s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89d697d6-cc34-468f-bd31-f2ab87de8481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/foo/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at anton-l/xtreme_s_xlsr_300m_minds14 were not used when initializing Wav2Vec2ForSequenceClassification: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at anton-l/xtreme_s_xlsr_300m_minds14 and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"audio-classification\",\n",
    "    model=\"anton-l/xtreme_s_xlsr_300m_minds14\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea26cf88-1975-4608-bb62-88fbf214b59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '/home/a_notable_alpaca/.cache/huggingface/datasets/downloads/extracted/6647af8fc432b0860cf489c57dcb5f6c7483fb05c037f9923015f60a77ad431b/en-AU~PAY_BILL/response_4.wav',\n",
       " 'audio': {'path': '/home/a_notable_alpaca/.cache/huggingface/datasets/downloads/extracted/6647af8fc432b0860cf489c57dcb5f6c7483fb05c037f9923015f60a77ad431b/en-AU~PAY_BILL/response_4.wav',\n",
       "  'array': array([2.36119668e-05, 1.92324660e-04, 2.19284790e-04, ...,\n",
       "         9.40907281e-04, 1.16613181e-03, 7.20883254e-04]),\n",
       "  'sampling_rate': 16000},\n",
       " 'transcription': 'I would like to pay my electricity bill using my card can you please assist',\n",
       " 'english_transcription': 'I would like to pay my electricity bill using my card can you please assist',\n",
       " 'intent_class': 13,\n",
       " 'lang_id': 2}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = minds[0]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58faed52-a9b9-4fef-9f8c-df31766df900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9625311493873596, 'label': 'pay_bill'},\n",
       " {'score': 0.028672724962234497, 'label': 'freeze'},\n",
       " {'score': 0.003349797800183296, 'label': 'card_issues'},\n",
       " {'score': 0.0020058038644492626, 'label': 'abroad'},\n",
       " {'score': 0.000848432828206569, 'label': 'high_value_payment'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(example[\"audio\"][\"array\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48d1dc77-1208-417b-b2e2-25003ba4d55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pay_bill'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = minds.features[\"intent_class\"].int2str\n",
    "id2label(example[\"intent_class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296a336f-2c3f-4d49-b3b6-3cdbc1536780",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea74f07-53f9-4248-9918-d6c914b8c040",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* [Fine-tuning XLS-R for Multi-Lingual ASR with ðŸ¤— Transformers](https://huggingface.co/blog/fine-tune-xlsr-wav2vec2) blog post explaining XLS-R and Wav2Vec2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f456b50-58de-4e54-98ef-6e57f6c4d726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
